{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# we will definitely need pyConText\n",
    "import pyConTextNLP\n",
    "from pyConTextNLP import pyConTextGraph\n",
    "from pyConTextNLP.itemData import itemData\n",
    "from pyConTextNLP.display.html import mark_document_with_html\n",
    "print(pyConTextNLP.__version__)\n",
    "# useful utilities in RadNLP as well\n",
    "import radnlp\n",
    "import radnlp.view as rview\n",
    "from radnlp.data import classrslts\n",
    "# we will need a few other packages\n",
    "from textblob import TextBlob\n",
    "import urllib\n",
    "import pandas as pd\n",
    "# packages for interaction\n",
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "from IPython.display import display, HTML, Image\n",
    "import ipywidgets\n",
    "# and also our utilities for this class\n",
    "from nlp_pneumonia_utils import Annotation\n",
    "from nlp_pneumonia_utils import AnnotatedDocument\n",
    "from nlp_pneumonia_utils import read_brat_annotations\n",
    "from nlp_pneumonia_utils import read_doc_annotations\n",
    "from nlp_pneumonia_utils import read_annotations\n",
    "from nlp_pneumonia_utils import calculate_prediction_metrics\n",
    "from nlp_pneumonia_utils import mark_text\n",
    "from nlp_pneumonia_utils import pneumonia_html_markup\n",
    "from nlp_pneumonia_utils import clearPyConTextRegularExpressions\n",
    "\n",
    "print('Imported pneumonia nlp utilities...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First thing, let's load our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotated_doc_map = read_doc_annotations('data/training.zip')\n",
    "#annotated_doc_map = read_doc_annotations('pneumonia_brat_full_set1.zip')\n",
    "# let's also use a simple list of documents as well as this map\n",
    "annotated_docs = list(annotated_doc_map.values())\n",
    "\n",
    "print('Total Annotated Documents : {0}'.format(len(annotated_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def markup_sentence(s, modifiers, targets, prune_inactive=True, verbose = False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    markup = pyConTextGraph.ConTextMarkup()\n",
    "    markup.setRawText(s)\n",
    "    markup.cleanText()\n",
    "    markup.markItems(targets, mode=\"target\")\n",
    "    markup.markItems(modifiers, mode=\"modifier\")\n",
    "    markup.pruneMarks()\n",
    "    markup.dropMarks('Exclusion')\n",
    "    # apply modifiers to any targets within the modifiers scope\n",
    "    markup.applyModifiers()\n",
    "    markup.pruneSelfModifyingRelationships()\n",
    "    if prune_inactive:\n",
    "        markup.dropInactiveModifiers()\n",
    "    return markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us set up an example document to work with\n",
    "example_document = \"\"\"\n",
    "PORTABLE CHEST:  Comparison made to prior film from X:XX a.m. the same day.\n",
    "     \n",
    "The ET tube and nasogastric tube remain in good position. Cardiac and\n",
    "mediastinal contours are stable. No acute changes are seen within the lung\n",
    "parenchyma; specifically, there is no evidence of new infiltrate (skin folds\n",
    "do project over the right lung). No consolidation on either side.\n",
    "\n",
    "IMPRESSION: No evidence of pneumonia.\"\"\"\n",
    "\n",
    "example_sentence = \"\"\"IMPRESSION: No evidence of pneumonia.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we continue, note that any itemData in pyConText has 4 parts:\n",
    "1. The literal (e.g. \"pneumonia\", \"pneumoniathorax\", \"can rule out\", \"cannot be excluded\", etc)\n",
    "2. The category (e.g. \"EVIDENCE_OF_PNEUMONIA\")\n",
    "3. The regular expression (optional) used to capture the literal in the text. If no regular expression is provided, a regular expression is generated literally from the literal.\n",
    "4. The rule (optional). If the itemData is being used as a modifier, the rule states what direction the modifier operates in the sentence: current valid values are: \"forward\", the item can modify objects following it in the sentence; \"backward\", the item can modify objects preceding it in the sentence; or \"bidirectional\", the item can modify objects preceding and following it in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's set up some rules for pyConText for EVIDENCE_OF_PNEUMONIA\n",
    "# At this moment, we will just set up these \"concepts\" and well handle modifiers for them after that\n",
    "\n",
    "targets1 = []\n",
    "modifiers1 = []\n",
    "\n",
    "# so before we add targets, remember from above that they will look like this : \n",
    "# targets = itemData([\"literal\", \"CATEGORY\", \"regular expression(s)\", \"empty or forward or backward or bidirectional\"])\n",
    "\n",
    "# so now let's set this up for \"pneumonia\" with the category \"EVIDENCE_OF_PNEUMONIA\"\n",
    "targets1 = itemData([\"pneumonia\", \"EVIDENCE_OF_PNEUMONIA\", \"\", \"\"])\n",
    "\n",
    "# let's go ahead and use this now on one single example sentence:\n",
    "markup = markup_sentence(example_sentence, modifiers1, targets1)\n",
    "# prettier display with IPython display\n",
    "display(markup.nodes(data = True))\n",
    "#print(markup.getXML())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function now works on entire documents combining all sentence-level objects into one object we can can then graph\n",
    "def markup_context_document(report_text, modifiers, targets):\n",
    "    context = pyConTextGraph.ConTextDocument()\n",
    "    \n",
    "    # we will use TextBlob for breaking up sentences\n",
    "    sentences = [s.raw for s in TextBlob(report_text).sentences]\n",
    "    for sentence in sentences:\n",
    "        m = markup_sentence(sentence, modifiers=modifiers, targets=targets)\n",
    "        context.addMarkup(m)\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_sentence_2 = \"\"\"Findings consistent with CHF, although underlying bilateral lower lobe pneumonias cannot be excluded.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see how things look on this sentence\n",
    "markup_sentence_2 = markup_sentence(example_sentence_2, modifiers1, targets1, verbose = True)\n",
    "display(markup_sentence_2.nodes(data = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So we didn't mark up a target for \"pneumonias\" since we only had the singular variant \"pneumonia\".  Let's add that as we augment our target concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pneumonia_targets_file = 'KB/pneumonia_targets.tsv'\n",
    "\n",
    "# let's see what we're working with by loading this as a Pandas DataFrame and then we can display it\n",
    "pneumonia_targets_df = pd.read_csv(pneumonia_targets_file, delimiter = '\\t')\n",
    "display(pneumonia_targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our first attempt was very simple target, so now let's add some additional concepts\n",
    "targets2 = []\n",
    "modifiers2 = []\n",
    "\n",
    "# so before we add targets, remember from above that they will look like this : \n",
    "# targets = itemData([\"literal\", \"CATEGORY\", \"regular expression(s)\", \"empty or forward or backward or bidirectional\"])\n",
    "\n",
    "# before we continue, let's clear a mapping of compiled regular expressions which pyConText uses\n",
    "clearPyConTextRegularExpressions()\n",
    "\n",
    "# so now let's set this up with more variants of \"EVIDENCE_OF_PNEUMONIA\"\n",
    "full_targets_path = 'file:///' + os.path.join(os.getcwd(), pneumonia_targets_file)\n",
    "print('Loading pneumonia targets from : ' + full_targets_path)\n",
    "targets2 = pyConTextNLP.itemData.instantiateFromCSVtoitemData(full_targets_path)\n",
    "\n",
    "# let's go ahead and use this again on our updated targets\n",
    "context = markup_context_document(example_document, modifiers2, targets2)\n",
    "# prettier display with IPython display\n",
    "display(context.getDocumentGraph().nodes(data = True))\n",
    "#print(context.getXML())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at this markup in HTML with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evidence_only_colors = {\n",
    "    \"evidence_of_pneumonia\": \"orange\"\n",
    "}\n",
    "\n",
    "context_html = pyConTextNLP.display.html.mark_document_with_html(context, colors = evidence_only_colors, default_color=\"black\")\n",
    "display(HTML(context_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's also look again to see if our regular expression for \"pneumonia\" and \"pneumonias\" worked properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markup_sentence_2_check = markup_sentence(example_sentence_2, modifiers2, targets2)\n",
    "print(targets2)\n",
    "display(markup_sentence_2_check.nodes(data = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We've  added some pyConText targets, so let's utilize them in a classifier so that we can see that adding targets can increase our Recall even if Precision suffers\n",
    "## We will address Precision when we start working with ConText Modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConTextTargetOnlyClassifier(object):\n",
    "    def __init__(self, modifiers, targets):\n",
    "        self.modifiers = modifiers\n",
    "        self.targets = targets\n",
    "    def predict(self, text):\n",
    "        # let's use our other functions in this notebook to perform sentence-wise markup and\n",
    "        # we can then check to see if these contain any EVIDENCE_OF_PNEUMONIA category types\n",
    "        context = markup_context_document(text, self.modifiers, self.targets)\n",
    "        document_graph = context.getDocumentGraph()\n",
    "        \n",
    "        # let's walk through all of the nodes in the graph and see how many are evidence of pneumonia\n",
    "        pneumonia_evidence_count = 0\n",
    "        for node in document_graph.nodes():\n",
    "            category_list = node.getCategory()\n",
    "            for category in category_list:\n",
    "                if category.upper() == 'EVIDENCE_OF_PNEUMONIA':\n",
    "                    pneumonia_evidence_count += 1\n",
    "            \n",
    "        # do we have at least one category of pneumonia evidence here?\n",
    "        return (pneumonia_evidence_count) > 0\n",
    "           \n",
    "# this one has only one target\n",
    "classifier1 = ConTextTargetOnlyClassifier(modifiers1, targets1)\n",
    "# this one has 3...\n",
    "classifier2 = ConTextTargetOnlyClassifier(modifiers2, targets2)\n",
    "\n",
    "# and now we can assess their performance\n",
    "print('****************')\n",
    "print('Performance for Classifier 1 : One total Target')\n",
    "calculate_prediction_metrics(annotated_docs, classifier1.predict)\n",
    "\n",
    "print('****************')\n",
    "print('Performance for Classifier 2 : 3 total Targets')\n",
    "calculate_prediction_metrics(annotated_docs, classifier2.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So we have improved recall, but what are we going to do about Precision  Since both Precision and Recall are measured equally in our F1 measure, we need to address it\n",
    "## The solution to this is to improve our classification pipeline with ConText Modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifiers are used to add objects which modify other tags or items in the sentence.  For example, we've already added targets for evidence of pneumonia.  We can now use modifiers to ensure that instead of treating each of these mentions as affirmed evidence, we can modify them by the context of other words in the sentence.\n",
    "## Concretely if we had a sentence \"No evidence of pneumonia\" our current pipelines would count this as a positive case of pneumonia when it is in fact the contrary.\n",
    "## We can add a rule \"no evidence of\" to modify all targets which follow it\n",
    "## Modifiers can also modify targets which came before it in a sentence such as \"pneumonia will be ruled out\"\n",
    "## Modifiers can have the following values:\n",
    "1. backward (modify any markup preceding it)\n",
    "2. forward (modify any markup following it)\n",
    "3. bidirectional (modify any markup following or preceding it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's set up some demonstrations of how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probable_sentence_1 = \"\"\"probable case of pneumonia\"\"\"\n",
    "probable_sentence_2 = \"\"\"no evidence of pneumonia and probable arthritis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def view_single_sentence_graph(sentence, modifiers, targets):\n",
    "    context = markup_context_document(sentence, modifiers, targets)\n",
    "    class_result = classrslts(context_document=context, exam_type=\"Chest X-Ray\", report_text=sentence, classification_result='N/A')\n",
    "    rview.markup_to_pydot(class_result)\n",
    "    display(Image(\"tmp.png\"))\n",
    "    print(sentence)\n",
    "    \n",
    "modifiers_forward = itemData([\"probable\", \"PROBABLE_EXISTENCE\", \"\", \"forward\"])\n",
    "modifiers_backward = itemData([\"probable\", \"PROBABLE_EXISTENCE\", \"\", \"backward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward in this sentence modifies what we would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see how we graph the relationships between targets and modifiers based on 'backward' or 'forward':\n",
    "clearPyConTextRegularExpressions()\n",
    "view_single_sentence_graph(probable_sentence_1, modifiers_forward, targets1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this example, nothing precedes \"probable\" so nothing to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see how we graph the relationships between targets and modifiers based on 'backward' or 'forward':\n",
    "clearPyConTextRegularExpressions()\n",
    "view_single_sentence_graph(probable_sentence_1, modifiers_backward, targets1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this example, the forward rule does not pick up pneumonia since it comes before and we've not set up a target for arthritis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see how we graph the relationships between targets and modifiers based on 'backward' or 'forward':\n",
    "clearPyConTextRegularExpressions()\n",
    "view_single_sentence_graph(probable_sentence_2, modifiers_forward, targets1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And in this example, when we allow the target to work backward, it picks up a context where there seems to be \"no evidence of pneumonia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see how we graph the relationships between targets and modifiers based on 'backward' or 'forward':\n",
    "clearPyConTextRegularExpressions()\n",
    "view_single_sentence_graph(probable_sentence_2, modifiers_backward, targets1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the proper syntax for rules helps us implement the proper directionality of what it modifies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is another important attribute that Modifiers can employ : \"terminate\"\n",
    "## This allows any modifier working forward or backward to stop its modifications if it encounters one of these terms.  Let's demonstrate an example where we want \"probable\" to modify \"arthritis\" as a condition but not \"pneumonia\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "terminate_example_sentence = \"\"\"probable arthritis but not pneumonia\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_targets = itemData([\"pneumonia\", \"EVIDENCE_OF_PNEUMONIA\", \"\", \"\"],\n",
    "                       [\"arthritis\", \"ANOTHER_CONDITION\", \"\", \"forward\"])\n",
    "\n",
    "modifiers_without_terminate = itemData([\"probable\", \"PROBABLE_EXISTENCE\", \"\", \"forward\"])\n",
    "\n",
    "modifiers_with_terminate = itemData([\"probable\", \"PROBABLE_EXISTENCE\", \"\", \"forward\"],\n",
    "                                   [\"but\", \"CONJ\", \"\", \"terminate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without the \"terminate\" modifier \"probable_existence\" is applied to both arthritis and also pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clearPyConTextRegularExpressions()\n",
    "view_single_sentence_graph(terminate_example_sentence, modifiers_without_terminate, temp_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the \"terminate\" modifier \"probable_existence\" is applied only to \"arthritis\" and does not modify beyond the conjunction \"but\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clearPyConTextRegularExpressions()\n",
    "view_single_sentence_graph(terminate_example_sentence, modifiers_with_terminate, temp_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing modifiers takes time and objective measure.  Luckily, many of them have already been developed by Dr. Wendy Chapman and others on various research efforts.  Let's see what kind of data they contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_modifiers_url = \"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/lexical_kb_05042016.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modifier_file = urllib.request.urlopen(context_modifiers_url, data=None)\n",
    "# now let's load this in directly into a DataFrame with Pandas and take a look at it\n",
    "modifier_df = pd.read_csv(modifier_file, delimiter = \"\\t\")\n",
    "display(modifier_df.head(10))\n",
    "display(modifier_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modifiers3 = pyConTextNLP.itemData.instantiateFromCSVtoitemData(context_modifiers_url)\n",
    "# let's just use the same targets as above for our third pipeline\n",
    "targets3 = targets2\n",
    "\n",
    "clearPyConTextRegularExpressions()\n",
    "\n",
    "print('Total Modifiers Loaded for pipeline #3 : [{0}]'.format(len(modifiers3)))\n",
    "print('Total Targets Loaded for pipeline #3 : [{0}]'.format(len(targets3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can use leverage both Targets and Modifiers to properly leverage context let's see what this looks like in HTML with our document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare some colors for displaying any markup we might see\n",
    "colors = {\n",
    "    \"evidence_of_pneumonia\": \"orange\",\n",
    "    \"definite_negated_existence\": \"red\",\n",
    "    \"probable_negated_existence\": \"indianred\",\n",
    "    \"ambivalent_existence\": \"orange\",\n",
    "    \"probable_existence\": \"forestgreen\",\n",
    "    \"definite_existence\": \"green\",\n",
    "    \"historical\": \"goldenrod\",\n",
    "    \"indication\": \"pink\",\n",
    "    \"acute\": \"golden\"\n",
    "}\n",
    "\n",
    "# let's mark up a new context object for our pipeline#3\n",
    "context3 = markup_context_document(example_document, modifiers3, targets3)\n",
    "\n",
    "display(HTML(pyConTextNLP.display.html.mark_document_with_html(context3, colors = colors, default_color=\"black\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now let's take a closer look at the XML to see how this is working behind the scenes\n",
    "print(context3.getXML())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, so now that we've got some decent Targets and Modifiers to start from, let's process all of the documents and then visualize the relationships between Targets and Modifiers for some of these documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# NOTE : This is a \"magic\" command to Jupyter to time the execution of this entire cell\n",
    "\n",
    "report_results = []\n",
    "print('Marking up all documents...')\n",
    "for anno_doc in annotated_docs:\n",
    "    report_context = markup_context_document(anno_doc.text, modifiers3, targets3)\n",
    "    # package this up into a class that the RadNLP utilities can use\n",
    "    results = classrslts(context_document=report_context, exam_type=\"Chest X-Ray\", report_text=anno_doc.text, classification_result='N/A')\n",
    "    report_results.append(results)\n",
    "    \n",
    "print('DONE Marking up all documents...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function let's us iterate through all documents and view the markup\n",
    "def view_markup(class_results, colors):\n",
    "    @interact(i=ipywidgets.IntSlider(min=0, max=len(class_results)-1))\n",
    "    def _view_markup(i):\n",
    "        class_result = class_results[i]\n",
    "        rview.markup_to_pydot(class_result)\n",
    "        display(Image(\"tmp.png\"))\n",
    "        \n",
    "        report_html = pyConTextNLP.display.html.mark_document_with_html(class_result.context_document, colors = evidence_only_colors, default_color=\"black\")\n",
    "        \n",
    "        display(HTML(report_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view_markup(report_results, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now that we can see how modifiers can interact with Targets, let's see if we can use a toy example to see how this can help improve Precision\n",
    "\n",
    "## NOTE : The simple classifier coded her below is not an example of how pyConText should truly be used.  Jianlin will talk about a cleaner way to set up classification rules, but until then we can use this approach to determine if we can improve Precision (i.e. reduce False Positives) by only classifying on 1 or more mentions of pneumonia evidence which are not negated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so now that we have added some pyConText targets, let's wire this up into a classifier so that we \n",
    "# can see that adding targets can increase our Recall even if Precision suffers\n",
    "# We will address Precision when we start working with ConText Modifiers\n",
    "class ConTextTargetModifierToyClassifier(object):\n",
    "    def __init__(self, modifiers, targets):\n",
    "        self.modifiers = modifiers\n",
    "        self.targets = targets\n",
    "        # here is a list of modifiers which we do not want to allow for \"positive\" classification\n",
    "        self.negative_modifier_set = set(['definite_negated_existence', 'probable_negated_existence'])\n",
    "        \n",
    "    def predict(self, text):\n",
    "        # let's use our other functions in this notebook to perform sentence-wise markup and\n",
    "        # we can then check to see if these contain any EVIDENCE_OF_PNEUMONIA category types\n",
    "        context = markup_context_document(text, self.modifiers, self.targets)\n",
    "        document_graph = context.getDocumentGraph()\n",
    "        \n",
    "        # NOTE : Not necessary to understand the code below as long as you understand that :\n",
    "        # we're now only counting \"positive pneumonia\" as long as it's not modified by one of the negative modifiers\n",
    "        # in \"self.negative_modifier_set\"\n",
    "        pneumonia_evidence_count = 0\n",
    "        # this returns tuples of (tagObject, dictionary)\n",
    "        nodes = document_graph.nodes(data = True)\n",
    "        nodes.sort()\n",
    "        for node in nodes:\n",
    "            tag_object = node[0]\n",
    "            for category in tag_object.getCategory():\n",
    "                if category.upper() == 'EVIDENCE_OF_PNEUMONIA':\n",
    "                    # let's fetch any nodes which \"modify\" our evidence\n",
    "                    modifier_category_set = set()\n",
    "                    modified_by = document_graph.predecessors(tag_object)\n",
    "                    if modified_by:\n",
    "                        for modifier in modified_by:\n",
    "                            modifier_category_set = modifier_category_set.union(set(modifier.getCategory()))\n",
    "                    # let's see if this node was modified by any of the set that we currently do not allow\n",
    "                    found_negative_modifiers = modifier_category_set.intersection(self.negative_modifier_set)\n",
    "                    if len(found_negative_modifiers) == 0:\n",
    "                        pneumonia_evidence_count += 1\n",
    "            \n",
    "        # do we have at least one category of pneumonia evidence here?\n",
    "        return (pneumonia_evidence_count) > 0\n",
    "    \n",
    "# instantiate our \"toy\" classifier which considers targets and their modifiers\n",
    "target_modifier_toy_classifier = ConTextTargetModifierToyClassifier(modifiers3, targets3)\n",
    "\n",
    "print('****************')\n",
    "print('Performance for Classifier 3 : Combining Targets and Modifiers')\n",
    "calculate_prediction_metrics(annotated_docs, target_modifier_toy_classifier.predict)\n",
    "\n",
    "# and let's compare this side-y-side with our previous classifier of targets-only\n",
    "print('****************')\n",
    "print('Performance for Classifier 1 : 3 total Targets')\n",
    "calculate_prediction_metrics(annotated_docs, classifier2.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving our system\n",
    "## Now that we have the tools of adding/editing Targets and Modifiers in pyConText we can continue our rounds of Error Analysis as Jianlin demonstrated to us previously (see \"NLP_ErrorAnalysis\" notebook) and we can examine cases of False Positives and False Negatives so that we can increase Precision and Recall respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_false_negatives(gold_docs, prediction_function):\n",
    "    fn_docs={}\n",
    "    for doc_name, gold_doc in gold_docs.items():\n",
    "        gold_label=gold_doc.positive_label;\n",
    "        pred_label = prediction_function(gold_doc.text)\n",
    "        if gold_label==1 and pred_label==0:\n",
    "            fn_docs[doc_name]=gold_doc            \n",
    "    return fn_docs  \n",
    "\n",
    "def list_false_positives(gold_docs, prediction_function):\n",
    "    fn_docs={}\n",
    "    for doc_name, gold_doc in gold_docs.items():\n",
    "        gold_label=gold_doc.positive_label;\n",
    "        pred_label = prediction_function(gold_doc.text)\n",
    "        if gold_label==0 and pred_label==1:\n",
    "            fn_docs[doc_name]=gold_doc            \n",
    "    return fn_docs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get our current set of false negatives and false positives if we use our simple toy classifier\n",
    "# which uses targets and a simplified implementation of modifiers\n",
    "current_false_negatives = list_false_negatives(annotated_doc_map, target_modifier_toy_classifier.predict)\n",
    "current_false_positives = list_false_positives(annotated_doc_map, target_modifier_toy_classifier.predict)\n",
    "\n",
    "# prepare each of these for visualization\n",
    "fn_report_results = []\n",
    "fp_report_results = []\n",
    "print('Marking up False Negatives')\n",
    "for anno_doc in current_false_negatives.values():\n",
    "    report_context = markup_context_document(anno_doc.text, modifiers3, targets3)\n",
    "    # package this up into a class that the RadNLP utilities can use\n",
    "    results = classrslts(context_document=report_context, exam_type=\"Chest X-Ray\", report_text=anno_doc.text, classification_result='N/A')\n",
    "    fn_report_results.append(results)\n",
    "    \n",
    "print('Marking up False Positives')\n",
    "for anno_doc in current_false_positives.values():\n",
    "    report_context = markup_context_document(anno_doc.text, modifiers3, targets3)\n",
    "    # package this up into a class that the RadNLP utilities can use\n",
    "    results = classrslts(context_document=report_context, exam_type=\"Chest X-Ray\", report_text=anno_doc.text, classification_result='N/A')\n",
    "    fp_report_results.append(results)\n",
    "\n",
    "print('Current total False Negatives : {0}'.format(len(current_false_negatives)))\n",
    "print('Current total False Positives : {0}'.format(len(current_false_positives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view_markup(fn_report_results, colors)\n",
    "print('Display for current False Negatives:')\n",
    "print('Current total False Negatives : {0}'.format(len(current_false_negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view_markup(fp_report_results, colors)\n",
    "print('Display for current False Positives:')\n",
    "print('Current total False Positives : {0}'.format(len(current_false_positives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
